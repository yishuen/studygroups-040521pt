{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic 20: Extensions to Linear Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review: Interpreting Multiple Linear Regression Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "data = pd.read_csv('auto-mpg.csv')\n",
    "\n",
    "acc = data['acceleration']\n",
    "logdisp = np.log(data['displacement'])\n",
    "loghorse = np.log(data['horsepower'])\n",
    "logweight= np.log(data['weight'])\n",
    "\n",
    "scaled_acc = (acc-min(acc))/(max(acc)-min(acc))\t\n",
    "scaled_disp = (logdisp-np.mean(logdisp))/np.sqrt(np.var(logdisp))\n",
    "scaled_horse = (loghorse-np.mean(loghorse))/(max(loghorse)-min(loghorse))\n",
    "scaled_weight= (logweight-np.mean(logweight))/np.sqrt(np.var(logweight))\n",
    "\n",
    "data_fin = pd.DataFrame([])\n",
    "data_fin['acc']= scaled_acc\n",
    "data_fin['disp']= scaled_disp\n",
    "data_fin['horse'] = scaled_horse\n",
    "data_fin['weight'] = scaled_weight\n",
    "mpg = data['mpg']\n",
    "data_fin = pd.concat([mpg, data_fin, data['cylinders'], data['model year'], data['origin']], axis=1)\n",
    "y = data_fin[['mpg']]\n",
    "X = data_fin.drop(['mpg'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "formula = 'mpg ~ acceleration+weight+horsepower+displacement'\n",
    "model = ols(formula=formula, data=data).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "* R-squared and adjusted R-squared\n",
    "    * R-squared is a measure of how well the model fits the data\n",
    "    * This model and these independent variables explain 71% of the variance in MPG\n",
    "    * Adjusted R-squared accounts for more independent variables\n",
    "* Coefficient\n",
    "    * Intercept: Coefficient of 45.2511 means that with all variables at 0, MPG would have a prediction of 45.2511\n",
    "    * Independent variables: A **one unit increase** in the independent variable will lead to a **coefficient amount** increase in the dependent variable\n",
    "* The Hypothesis (per each independent variable)\n",
    "    * $H_0$: coefficient = 0\n",
    "    * $H_A$: coefficient != 0\n",
    "    * We're looking to see if there's a relationship between each independent variable and the dependent variable\n",
    "    * **t-statistic** is the t-stat from this t-test of whether the coefficient is equal to zero\n",
    "    * **p-value** -- a p-value below 0.05 (if alpha = 0.05) is evidence to **reject the null hypothesis** so there is statistical evidence that there is a relationship between independent and dependent variable\n",
    "    * a p-value above 0.05 is saying that **statistically**, there is no relationship between independent and dependent variable\n",
    "    * The p-value is the associated p-value of the **t-statistic** -- therefore if the t-statistic is **outside the [0.025-0.975] confidence interval**, the p-value should be below 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a. Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using train-test split, random samples of data are created for the training and the test set. The problem with this is that the training and test MSE strongly depend on how the training and test sets were created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "linreg = LinearRegression()\n",
    "\n",
    "num = 20\n",
    "train_err = []\n",
    "test_err = []\n",
    "for i in range(num):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "    linreg.fit(X_train, y_train)\n",
    "    y_hat_train = linreg.predict(X_train)\n",
    "    y_hat_test = linreg.predict(X_test)\n",
    "    train_err.append(mean_squared_error(y_train, y_hat_train))\n",
    "    test_err.append(mean_squared_error(y_test, y_hat_test))\n",
    "plt.plot(list(range(num)), train_err, label='Training Error')\n",
    "plt.plot(list(range(num)), test_err, label='Testing Error')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv_5_results = cross_val_score(linreg, X, y, cv=10,  scoring='neg_mean_squared_error')\n",
    "print(cv_5_results)\n",
    "np.mean(cv_5_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(linreg, X, y, scoring='r2', cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b. Bias-Variance Trade-Off"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *Underfitting* (bias) happens when a model cannot learn the training data, nor can it generalize to new data.\n",
    "\n",
    "- Bias arises when wrong assumptions are made when training a model. For example, an interaction effect is missed, or we didn't catch a certain polynomial relationship. Because of this, our algorithm misses the relevant relations between predictors and the target variable. Note how this is similar to underfitting!\n",
    "\n",
    "> *Overfitting* (variance) happens when a model learns the training data too well. In fact, so well that it is not generalizeable to new data \n",
    "\n",
    "- Variance arises  when a model is too sensitive to small fluctuations in the training set. When variance is high, random noise in the training data is modeled, rather than the intended outputs. This is overfitting!\n",
    "\n",
    "<img src=\"images/modelfit.png\" width=\"700\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c. Interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yr_old = data_fin[:180] # cars from 70 to 75\n",
    "yr_young = data_fin[180:] # cars from 76 to 82"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_1 = LinearRegression()\n",
    "regression_2 = LinearRegression()\n",
    "\n",
    "horse_1 = yr_old['horse'].values.reshape(-1, 1)\n",
    "horse_2 = yr_young['horse'].values.reshape(-1, 1)\n",
    "\n",
    "regression_1.fit(horse_1, yr_old['mpg'])\n",
    "regression_2.fit(horse_2, yr_young['mpg'])\n",
    "\n",
    "# Make predictions using the testing set\n",
    "pred_1 = regression_1.predict(horse_1)\n",
    "pred_2 = regression_2.predict(horse_2)\n",
    "\n",
    "# The coefficients\n",
    "print(regression_1.coef_)\n",
    "print(regression_2.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot outputs\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "plt.scatter(horse_1, yr_old['mpg'],  color='blue', alpha = 0.3, label = 'older cars')\n",
    "plt.scatter(horse_2, yr_young['mpg'],  color='red', alpha = 0.3, label = 'younger cars')\n",
    "\n",
    "plt.plot(horse_1, pred_1,  color='blue', linewidth=2)\n",
    "plt.plot(horse_2, pred_2,  color='red', linewidth=2)\n",
    "\n",
    "plt.ylabel('mpg')\n",
    "plt.xlabel('horsepower')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's first look at the baseline model, one without the interaction\n",
    "from sklearn.model_selection import KFold\n",
    "regression = LinearRegression()\n",
    "crossvalidation = KFold(n_splits=3, shuffle=True, random_state=1)\n",
    "\n",
    "baseline = np.mean(cross_val_score(regression, X, y, scoring='r2', cv=crossvalidation))\n",
    "baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression = LinearRegression()\n",
    "crossvalidation = KFold(n_splits=3, shuffle=True, random_state=1)\n",
    "\n",
    "X_interact_2 = X.copy()\n",
    "X_interact_2['horse_year'] = X['horse'] * X['model year']\n",
    "\n",
    "interact_horse_origin = np.mean(cross_val_score(regression, X_interact_2, y, scoring='r2', cv=crossvalidation))\n",
    "interact_horse_origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_interact_2 = sm.add_constant(X_interact_2)\n",
    "model = sm.OLS(y,X_interact_2)\n",
    "results = model.fit()\n",
    "\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## d. Polynomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yld = pd.read_csv('yield.csv', sep='\\s+', index_col=0)\n",
    "display(yld.head())\n",
    "plt.scatter(yld['Temp'], yld['Yield'], color='green')\n",
    "plt.xlabel('Temperature')\n",
    "plt.ylabel('Yield');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = yld['Yield']\n",
    "X = yld.drop(columns='Yield', axis=1)\n",
    "\n",
    "reg = LinearRegression().fit(X, y)\n",
    "plt.scatter(X, y, color='green')\n",
    "plt.plot(X, reg.predict(X))\n",
    "plt.xlabel('Temperature')\n",
    "plt.ylabel('Yield');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "print(np.sqrt(mean_squared_error(y, reg.predict(X))))\n",
    "print(r2_score(y, reg.predict(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['Temp_sq'] = X['Temp']**2\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_q = LinearRegression().fit(X, y)\n",
    "plt.scatter(X['Temp'], y, color='green')\n",
    "plt.plot(X['Temp'], reg_q.predict(X))\n",
    "plt.xlabel('Temperature')\n",
    "plt.ylabel('Yield')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sqrt(mean_squared_error(y, reg_q.predict(X))))\n",
    "print(r2_score(y, reg_q.predict(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sm.add_constant(X)\n",
    "model = sm.OLS(y,X)\n",
    "results = model.fit()\n",
    "\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
