{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic 16: AB Testing\n",
    "\n",
    "* Power Analysis\n",
    "* Run an A/B test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Power Analysis\n",
    "\n",
    "As you've seen, power analysis allows you to determine the sample size required to detect an effect of a given size with a given degree of confidence. In other words, it allows you to determine the probability of detecting an effect of a given size with a given level of confidence, under-sample size constraints.\n",
    "\n",
    "The following four factors have an intimate relationship:\n",
    "\n",
    "1. Sample size ($n$)\n",
    "2. Effect size ($d$)\n",
    "3. Significance level ($\\alpha$)= P (Type I error) = probability of finding an effect that is not there\n",
    "4. Power ($\\beta$) = 1 - P (Type II error) = probability of finding an effect that is there\n",
    "\n",
    "\n",
    "Given any three of these, we can easily determine the fourth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario\n",
    "\n",
    "A researcher wants to study how daily protein supplementation in the elderly population will affect baseline liver fat. The study budget will allow enrollment of **24 patients**. Half will be randomized to a placebo group and half to the protein supplement treatment group and the trial will be carried out over one month. It is desired to see whether the mean change in percentage of liver fat from baseline to the end of the study differs between the two groups in the study."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Up Power Analysis Simulation\n",
    "\n",
    "$$H_0: \\mu_{1} = \\mu_{2}$$\n",
    "$$H_0: \\mu_{1} \\neq \\mu_{2}$$\n",
    "\n",
    "$$\\alpha = 0.05$$\n",
    "\n",
    "The researcher needs to know what power will be obtained under the sample size restrictions to identify a change in mean percent liver fat of **0.17**. Based on past results, a common standard deviation of 0.21 will be used for each treatment group in the power analysis.\n",
    "\n",
    "In this experiment, we are constrained by our sample size (12), effect size (0.17 difference) and alpha (0.05). We want to find the **proportion of simulations where the null hypothesis is rejected**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of patients in each group\n",
    "sample_size = 12\n",
    "\n",
    "# Control group\n",
    "control_mean = 0\n",
    "control_sd = 0.21\n",
    "\n",
    "# Experimental group\n",
    "experimental_mean = 0.17 # this is our mu2!!\n",
    "experimental_sd = 0.21\n",
    "\n",
    "# Set the number of simulations for our test = 1000\n",
    "n_sim = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_ind.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For reproducibility \n",
    "np.random.seed(10)\n",
    "\n",
    "# Initialize array to store results\n",
    "p = (np.empty(n_sim))\n",
    "p.fill(np.nan)\n",
    "\n",
    "#  Run a for loop for range of values in n_sim\n",
    "\n",
    "for s in range(n_sim):\n",
    "    \n",
    "    # generating random variables with control/experimental parameters\n",
    "    control = np.random.normal(loc= control_mean, scale=control_sd, size=sample_size)\n",
    "    experimental = np.random.normal(loc= experimental_mean, scale=experimental_sd, size=sample_size)\n",
    "    \n",
    "    # running a 2-sample t test\n",
    "    t_test = stats.ttest_ind(control, experimental)\n",
    "    \n",
    "    # t_test is a tuple containing: (t-statistic, p-value)\n",
    "    p[s] = t_test[1]\n",
    "    \n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of null hypothesis rejections\n",
    "num_null_rejects = np.sum(p < 0.05)\n",
    "power = num_null_rejects/float(n_sim)\n",
    "\n",
    "power"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Achieving Power by Increasing Sample Size\n",
    "\n",
    "Often in behavioral research 0.8 is accepted as a sufficient level of power.\n",
    "\n",
    "https://www.statsmodels.org/stable/generated/statsmodels.stats.power.tt_ind_solve_power.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.power import TTestIndPower\n",
    "power = TTestIndPower()\n",
    "power.solve_power(effect_size=0.17/0.21, alpha=0.05, power=0.8)\n",
    "\n",
    "# round up for minimum sample size to achieve power = 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterative Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing\n",
    "target = 0.8\n",
    "sample_size = 12\n",
    "null_rejected = 0\n",
    "n_sim = 10000\n",
    "\n",
    "np.random.seed(10)\n",
    "\n",
    "p = (np.empty(n_sim))\n",
    "p.fill(np.nan)\n",
    "\n",
    "# Keep iterating until desired power is obtained\n",
    "\n",
    "power_sample = []\n",
    "while null_rejected < target:\n",
    "\n",
    "    data = np.empty([n_sim, sample_size, 2])\n",
    "    data.fill(np.nan)\n",
    "    \n",
    "    # For control group \n",
    "    # Here we specify size=[n_sim, sample_size] which creates an array of n_sim number of arrays,\n",
    "    # each containing sample_size number of elements. \n",
    "    # This is equivalent to manually looping n_sim times like we did above but is much faster.\n",
    "    data[:,:,0] = np.random.normal(loc=control_mean, scale=control_sd, size=[n_sim, sample_size])\n",
    "    \n",
    "    # For experimental group\n",
    "    data[:,:,1] = np.random.normal(loc=experimental_mean, scale=experimental_sd, size=[n_sim, sample_size])            \n",
    "    \n",
    "    result = stats.ttest_ind(data[:, :, 0],data[:, :, 1],axis=1)\n",
    "                                \n",
    "    p_vals = result[1]\n",
    "\n",
    "    # Since you know that all simulations are from a different distribution \\\n",
    "    # all those that rejected the null-hypothesis are valid\n",
    "    null_rejected = np.sum(p_vals < 0.05) / n_sim\n",
    "\n",
    "    print('Number of Samples:', sample_size,', Calculated Power =', null_rejected)\n",
    "    power_sample.append([sample_size, null_rejected])\n",
    "\n",
    "    # increase the number of samples by one for the next iteration of the loop\n",
    "    sample_size += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.title('Power vs. Sample Size')\n",
    "plt.xlabel('Sample Size')\n",
    "plt.ylabel('Power')\n",
    "\n",
    "ans = power_sample\n",
    "df = pd.DataFrame(ans, index=None)\n",
    "plt.plot(df[0], df[1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AB Testing\n",
    "\n",
    "Let's see if a change to a webpage led to more clicks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('homepage_actions.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Quick EDA..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cids = set(df[df.action=='click']['id'].unique())\n",
    "vids = set(df[df.action=='view']['id'].unique())\n",
    "print(\"Number of viewers: {} \\tNumber of clickers: {}\".format(len(vids), len(cids)))\n",
    "print(\"Number of viewers who didn't click: {}\".format(len(vids-cids)))\n",
    "print(\"Number of clickers who didn't view: {}\".format(len(cids-vids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control = df[df['group']=='control']\n",
    "experiment = df[df['group']=='experiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['count'] = 1\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Convert clicks into a binary variable on a user-by-user-basis\n",
    "control = df[df.group=='control'].pivot(index='id', columns='action', values='count')\n",
    "control = control.fillna(value=0)\n",
    "\n",
    "experiment = df[df.group=='experiment'].pivot(index='id', columns='action', values='count')\n",
    "experiment = experiment.fillna(value=0)\n",
    "\n",
    "print(\"Sample sizes:\\tControl: {}\\tExperiment: {}\".format(len(control), len(experiment)))\n",
    "print(\"Total Clicks:\\tControl: {}\\tExperiment: {}\".format(control.click.sum(), experiment.click.sum()))\n",
    "print(\"Average click rate:\\tControl: {}\\tExperiment: {}\".format(control.click.mean(), experiment.click.mean()))\n",
    "control.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### t-test formulas from old labs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def welch_t(a, b):\n",
    "    \n",
    "    \"\"\" Calculate Welch's t statistic for two samples. \"\"\"\n",
    "\n",
    "    numerator = a.mean() - b.mean()\n",
    "    \n",
    "    # “ddof = Delta Degrees of Freedom”: the divisor used in the calculation is N - ddof, \n",
    "    #  where N represents the number of elements. By default ddof is zero.\n",
    "    \n",
    "    denominator = np.sqrt(a.var(ddof=1)/a.size + b.var(ddof=1)/b.size)\n",
    "    \n",
    "    return np.abs(numerator/denominator)\n",
    "\n",
    "def welch_df(a, b):\n",
    "    \n",
    "    \"\"\" Calculate the effective degrees of freedom for two samples. This function returns the degrees of freedom \"\"\"\n",
    "    \n",
    "    s1 = a.var(ddof=1) \n",
    "    s2 = b.var(ddof=1)\n",
    "    n1 = a.size\n",
    "    n2 = b.size\n",
    "    \n",
    "    numerator = (s1/n1 + s2/n2)**2\n",
    "    denominator = (s1/ n1)**2/(n1 - 1) + (s2/ n2)**2/(n2 - 1)\n",
    "    \n",
    "    return numerator/denominator\n",
    "\n",
    "\n",
    "def p_value_welch_ttest(a, b, two_sided=False):\n",
    "    \"\"\"Calculates the p-value for Welch's t-test given two samples.\n",
    "    By default, the returned p-value is for a one-sided t-test. \n",
    "    Set the two-sided parameter to True if you wish to perform a two-sided t-test instead.\n",
    "    \"\"\"\n",
    "    t = welch_t(a, b)\n",
    "    df = welch_df(a, b)\n",
    "    \n",
    "    p = 1-stats.t.cdf(np.abs(t), df)\n",
    "    \n",
    "    if two_sided:\n",
    "        return 2*p\n",
    "    else:\n",
    "        return p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_value_welch_ttest(control.click, experiment.click, two_sided=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or using scipy:\n",
    "\n",
    "stats.ttest_ind(control.click, experiment.click)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
